#!/usr/bin/env bash
# Start AI project development

# Environment setup
# -----------------------------------------------------------------------------
set -o pipefail
[[ ${DEBUG-} ]] && set -o xtrace
SCRIPT_DIR="$(cd "${BASH_SOURCE[0]%/*}" || exit 1; pwd)"
[[ ":${PATH}:" != *:"${SCRIPT_DIR}":* ]] && export PATH="${SCRIPT_DIR}:${PATH}"
source "${SCRIPT_DIR}/bash_modules/terminal.sh"
source "${SCRIPT_DIR}/bash_modules/settings.sh"
source "${SCRIPT_DIR}/bash_modules/utils.sh"
source "${SCRIPT_DIR}/bash_modules/ai.sh"
[[ -z ${BASH_MODULES_DIR-} ]] && echo "ERROR: terminal.sh module missing" && exit 1

function print_usage() {
  cat <<EOF
Usage: $(basename "$0") [--ai <service_class>] [prompt]

Start AI project development

Dependencies:
  claude, gemini, aichat   AI CLI tools

Optional arguments:
  --ai <service_class>  Use specific AI service class (alpha, beta, gamma)
  prompt               Custom prompt to use instead of default file-based prompts
  -h, --help           Show this help message and exit

EOF
}

function format_ai_command_display() {
  local ai_command="$1"

  # Check if command contains single quotes (indicating a long prompt)
  if [[ "${ai_command}" == *\'* ]]; then
    local command_start="${ai_command%%\'*}"
    local command_end="${ai_command##*\'}"
    echo "${command_start}'...'${command_end}"
  else
    echo "${ai_command}"
  fi
}

# Parse arguments
declare ai_service_class=""
declare custom_prompt=""
while [[ $# -gt 0 ]]; do
  case "${1}" in
    -h|--help)
      print_usage
      exit 0
      ;;
    --ai)
      if [[ -z "${2}" ]]; then
        log_error "ERROR: --ai requires a service class argument (alpha, beta, gamma)"
        exit 1
      fi
      ai_service_class="${2}"
      shift 2
      ;;
    -*)
      log_error "ERROR: Unknown option '${1}'"
      print_usage
      exit 1
      ;;
    *)
      if [[ -n "${custom_prompt}" ]]; then
        log_error "ERROR: Only one prompt argument allowed"
        print_usage
        exit 1
      fi
      custom_prompt="${1}"
      shift
      ;;
  esac
done

function ctrlc_trap() {
  log_newline
  log_warning "Script interrupted. Exiting."
  exit 130
}
trap ctrlc_trap SIGINT

# Title and Dependency Checks
# -----------------------------------------------------------------------------
log_title "Starting AI Agent"

# Determine AI service class - default to alpha for interactive work
declare service_class="alpha"
if [[ -n "${ai_service_class}" ]]; then
  service_class="${ai_service_class}"
fi

declare model_tier
case "${service_class}" in
  alpha)
    model_tier="mid"
    ;;
  beta|gamma)
    model_tier="pro"
    ;;
  *)
    model_tier="fast"
    ;;
esac

log_message "Using AI service class: '${service_class}'"

# Validation Checks
# -----------------------------------------------------------------------------
if [[ -n "${ai_service_class}" ]]; then
  case "${ai_service_class}" in
    alpha|beta|gamma)
      # Valid service classes
      ;;
    *)
      log_error "ERROR: Invalid service class '${ai_service_class}'. Valid options: alpha, beta, gamma"
      exit 1
      ;;
  esac
fi

# Main Logic - Exit Early Pattern
# -----------------------------------------------------------------------------

declare role_file="ROLE.md"
if [[ ! -f "ROLE.md" ]]; then
  role_file=""
fi

# Handle custom prompt override - execute immediately and exit
if [[ -n "${custom_prompt}" ]]; then
  log_message "Using custom prompt"
  ai_command=$(ai_get_command "${service_class}" "${model_tier}" "${role_file}" "${custom_prompt}")
  log_message "Executing AI command..."
  log_message "❯ $(format_ai_command_display "${ai_command}")"
  eval "${ai_command}"
  exit 0
fi

declare prompt=""
declare env_prompt="Read the ${HOME}/reference/ENVIRONMENT.md file for environment context. "
env_prompt+="Read the ${HOME}/reference/INDEX.csv for documentation context."
declare agents_prompt="Read the AGENTS.md file for repository context."
declare agents_suffix="Respond with concise bullet points of the AGENTS.md content."
declare project_prompt="Read the PROJECT.md document. Respond with the project title, the shortest possible summary of completed work, and the remaining phases/tasks as a numbered list."
declare greeting_prompt="Respond with a simple greeting."

# Build pattern based on file existence
declare pattern=""
[[ -f "${HOME}/reference/ENVIRONMENT.md" ]] && pattern+="E"
[[ -f "AGENTS.md" ]] && pattern+="A"
[[ -f "PROJECT.md" ]] && pattern+="P"

# Set prompt based on file combination pattern
case "${pattern}" in
  "EAP") prompt="${env_prompt} ${agents_prompt} ${project_prompt}" ;;
  "AP")  prompt="${agents_prompt} ${project_prompt}" ;;
  "EA")  prompt="${env_prompt} ${agents_prompt} ${agents_suffix}" ;;
  "EP")  prompt="${env_prompt} ${project_prompt}" ;;
  "E")   prompt="${env_prompt} ${greeting_prompt}" ;;
  "P")   prompt="${project_prompt}" ;;
  "A")   prompt="${agents_prompt} ${agents_suffix}" ;;
  *)     prompt="${greeting_prompt}" ;;
esac

# Execute AI command with determined role file and prompt
# -----------------------------------------------------------------------------
ai_command=$(ai_get_command "${service_class}" "${model_tier}" "${role_file}" "${prompt}")
log_message "Executing AI command..."
log_message "❯ $(format_ai_command_display "${ai_command}")"
eval "${ai_command}"
